---
title: "simulation_SNF"
author: "Yuhan Xu"
date: "2025-09-02"
output: pdf_document
---

```{r}
set.seed(2025)

library(dplyr)
library(tidyr)
library(stringr)
library(readr)
library(glmnet)
library(Matrix)
library(ranger)
library(forcats)
library(ggplot2)

`%||%` <- function(a, b) if (!is.null(a)) a else b

```


```{r}
pre_path  <- "~/Desktop/Skilled Nursing Facility Cost Report/Final_SNF_CostReport_Cleaned_2012_2019.csv"
post_path <- "~/Desktop/Skilled Nursing Facility Cost Report/Final_SNF_CostReport_Cleaned_2012_2019.csv"

df_pre  <- read_csv(pre_path, show_col_types = FALSE)
df_post <- read_csv(post_path, show_col_types = FALSE)

id_col <- c("Provider CCN","Provider_CCN","provider_ccn")
id_col <- id_col[id_col %in% names(df_pre)][1]
if(is.na(id_col)) stop("Provider CCN was not found in the pre data. Please confirm the list.")

if(!("Year" %in% names(df_pre))) stop("The Year column was not found.")

y_candidates <- c("Net Income","Net Income from Service to Patients")
y_var <- y_candidates[y_candidates %in% names(df_pre)][1]
if(is.na(y_var)) stop("The target variable (Net Income or Net Income from Service to Patients) was not found.")

drop_cols <- c(id_col,"Year",y_var)

common_feats <- intersect(setdiff(names(df_pre), drop_cols), setdiff(names(df_post), drop_cols))
if(length(common_feats) < 5) stop("There are too few common features. Please check the column name consistency of the two cleaned data.")

pre <- df_pre %>% select(all_of(c(id_col,"Year",y_var, common_feats)))
post <- df_post %>% select(all_of(c(id_col,"Year",y_var, common_feats)))

pre <- pre %>% filter(!is.na(.data[[y_var]]))
```


```{r}
# ------------------------------
# 2) beta_star
# ------------------------------

pre$Year  <- as.factor(pre$Year)
post$Year <- as.factor(post$Year)

pre$Year  <- as.factor(pre$Year)
post$Year <- as.factor(post$Year)

esc <- function(v) ifelse(grepl("^[A-Za-z.][A-Za-z0-9_.]*$", v), v, paste0("`", v, "`"))

feat_escaped <- esc(c("Year", common_feats))
fml <- as.formula(paste("~", paste(feat_escaped, collapse = "+")))

pre$Year  <- as.factor(pre$Year)
post$Year <- as.factor(post$Year)

esc <- function(v) ifelse(grepl("^[A-Za-z.][A-Za-z0-9_.]*$", v), v, paste0("`", v, "`"))

feat_escaped <- esc(c("Year", common_feats))
fml_global <- as.formula(paste("~", paste(feat_escaped, collapse = "+")))

X_pre  <- model.matrix(fml_global, data = pre)
y_pre  <- pre[[y_var]]
X_post <- model.matrix(fml_global, data = post)

col_names <- colnames(X_pre)
if(!all(colnames(X_post) == col_names)) {
  X_post <- X_post[, col_names, drop = FALSE]
}

col_names <- colnames(X_pre)
if(!all(colnames(X_post) == col_names)) {
  X_post <- X_post[, col_names, drop = FALSE]
}


ols_fit <- lm(y_pre ~ X_pre[,-1])  

beta_star <- coef(lm.fit(x = X_pre, y = y_pre)) 

sigma_pre <- sd(y_pre - as.vector(X_pre %*% beta_star), na.rm = TRUE)

sd_alpha <- 0.10 * sd(y_pre, na.rm = TRUE)

col_names <- colnames(X_pre)
if(!all(colnames(X_post) == col_names)) {

  X_post <- X_post[, col_names, drop = FALSE]
}

```


```{r}
# ------------------------------
# 3) Utility functions
# ------------------------------
rmse <- function(a,b) sqrt(mean((a-b)^2, na.rm = TRUE))
mae  <- function(a,b) mean(abs(a-b), na.rm = TRUE)
bias <- function(a,b) mean(a-b, na.rm = TRUE)
sign_acc <- function(a, b, prev) {

  mean(sign(a) == sign(b), na.rm = TRUE)
}

median_imputer <- function(df_train, df_new) {
  impute_vals <- sapply(df_train, function(x){
    if(is.numeric(x)) median(x, na.rm = TRUE) else NA
  })
  for(nm in names(df_new)) {
    if(is.numeric(df_new[[nm]]) && nm %in% names(impute_vals)) {
      idx <- which(is.na(df_new[[nm]]))
      if(length(idx)) df_new[[nm]][idx] <- impute_vals[[nm]]
    }
  }
  df_new
}
```


```{r}
simulate_DGP <- function(
  scenario = c("A1","A2","C2"),
  drift_vars = NULL,
  drift_scale = 0.2,      # A2: relative change ratio of the coefficient
  delta_frac_IQR = -0.25, # A1: Intercept impact
  mar_rate = 0.15,        # C2: Missing proportion
  a3_sigma_mult = 1.0,    # A3: error variance amplification factor
  b1_shift = NULL         # B1: Covariate shift list
){
  scenario <- match.arg(scenario)

  if (!exists("fml_global", inherits = TRUE)) {
    esc <- function(v) ifelse(grepl("^[A-Za-z.][A-Za-z0-9_.]*$", v), v, paste0("`", v, "`"))
    feat_escaped <- esc(c("Year", common_feats))
    fml_global <<- as.formula(paste("~", paste(feat_escaped, collapse = "+")))
  }
  if (!exists("col_names", inherits = TRUE)) {
    X_pre_tmp <- model.matrix(fml_global, data = pre)
    col_names <<- colnames(X_pre_tmp)
  }

  ids_all   <- unique(c(pre[[id_col]], post[[id_col]]))
  alpha_map <- setNames(rnorm(length(ids_all), 0, sd_alpha), ids_all)
  alpha_pre  <- alpha_map[ as.character(pre[[id_col]]) ]
  alpha_post <- alpha_map[ as.character(post[[id_col]]) ]

  beta_post <- beta_star
  delta <- 0
  X_post_aug <- X_post  

  # --- A1: Intercept impact ---
  if (scenario == "A1") {
    delta <- delta_frac_IQR * IQR(y_pre, na.rm = TRUE)
  }

  # --- A2: Partial coefficient drift ---
  if (scenario == "A2") {
    if (is.null(drift_vars)) {
      set.seed(1314)
      drift_vars <- sample(common_feats, size = min(3, length(common_feats)))
    }
    for (v in drift_vars) {
      idx <- which(col_names == v)
      if (length(idx) == 1) {
        sgn <- sample(c(-1, 1), size = 1)
        beta_post[idx] <- beta_post[idx] * (1 + sgn * drift_scale)
      }
    }
  }

  # --- C2: MAR missing & median interpolation ---
  if (scenario == "C2") {
    pref <- c("Total Costs","Total Liabilities","Total Assets","Accounts Receivable","Total Charges")
    driver <- pref[pref %in% common_feats][1]
    if (is.na(driver)) {
      num_vars <- common_feats[sapply(post[common_feats], is.numeric)]
      driver <- num_vars[ which.max(sapply(post[num_vars], function(x) var(x, na.rm = TRUE))) ]
    }

    z <- scale(post[[driver]])
    p_miss <- plogis(-1 + 1.2 * as.numeric(z))  # driver 越大越易缺
    s <- quantile(p_miss, probs = 1 - mar_rate, na.rm = TRUE)
    mask <- p_miss > s
    stopifnot(length(mask) == nrow(post))

    set.seed(2468)
    miss_cols <- sample(common_feats, size = max(3, floor(length(common_feats) * 0.2)))

    Xraw_post <- post[, common_feats, drop = FALSE]
    if (length(miss_cols) > 0) Xraw_post[mask, miss_cols] <- NA

    Ximp_post <- median_imputer(pre[, common_feats, drop = FALSE], Xraw_post)

    X_post_aug <- model.matrix(fml_global,
                               data = cbind(post[, c("Year"), drop = FALSE], Ximp_post))
    miss_in_aug <- setdiff(col_names, colnames(X_post_aug))
    if (length(miss_in_aug) > 0) {
      for (nm in miss_in_aug) {
        X_post_aug <- cbind(X_post_aug, setNames(matrix(0, nrow(X_post_aug), 1), nm))
      }
    }
    X_post_aug <- X_post_aug[, col_names, drop = FALSE]
  }

  # --- B1: Covariate shift ---
  if (!is.null(b1_shift)) {

    post_num <- post[, common_feats, drop = FALSE]
    num_cols <- names(post_num)[sapply(post_num, is.numeric)]
    if (length(num_cols) > 0) {
      mu_shift <- b1_shift$mu_shift %||% 0    
      sd_scale <- b1_shift$sd_scale %||% 1.0
      ref_med  <- sapply(pre[, num_cols, drop = FALSE], median, na.rm = TRUE)
      post_num[num_cols] <- Map(function(x, m){
        (x - m) * sd_scale + m + mu_shift * abs(m)
      }, post_num[num_cols], ref_med)
    }

    # Rural/Urban proportion
    ru_name <- "Rural versus Urban"
    if (ru_name %in% common_feats) {
      ru <- as.character(post[[ru_name]])
      target_pp <- b1_shift$rural_pp %||% 0  
      if (target_pp != 0) {
        is_na <- is.na(ru)
        ru0 <- ru[!is_na]
        n   <- length(ru0)
        add_R <- round(target_pp * n)
        if (add_R > 0 && any(ru0 == "U")) {
          idx <- sample(which(ru0 == "U"), size = min(add_R, sum(ru0 == "U")))
          ru0[idx] <- "R"
        } else if (add_R < 0 && any(ru0 == "R")) {
          idx <- sample(which(ru0 == "R"), size = min(-add_R, sum(ru0 == "R")))
          ru0[idx] <- "U"
        }
        ru[!is_na] <- ru0
        post[[ru_name]] <- factor(ru, levels = unique(ru))
      }
    }

    # 用移位后的数值重建 X_post_aug（与 col_names 对齐）
    X_post_candidate <- model.matrix(fml_global,
      data = cbind(post[, c("Year"), drop = FALSE], post_num))
    miss_in_cand <- setdiff(col_names, colnames(X_post_candidate))
    if (length(miss_in_cand) > 0) {
      for (nm in miss_in_cand) {
        X_post_candidate <- cbind(X_post_candidate, setNames(matrix(0, nrow(X_post_candidate), 1), nm))
      }
    }
    X_post_aug <- X_post_candidate[, col_names, drop = FALSE]
  }

  eps_pre  <- rnorm(nrow(pre),  0, sigma_pre)
  eps_post <- rnorm(nrow(post), 0, sigma_pre * a3_sigma_mult)

  y_pre_syn  <- alpha_pre  + as.vector(X_pre  %*% beta_star) + eps_pre
  y_post_syn <- delta + alpha_post + as.vector(X_post_aug %*% beta_post) + eps_post

  list(
    X_pre  = X_pre,
    X_post = X_post_aug,
    y_pre  = y_pre_syn,
    y_post = y_post_syn,
    drift_vars = if (scenario == "A2") drift_vars else character(0),
    scenario = scenario
  )
}

```


```{r}
# ------------------------------
# 5) Training and Evaluation
# ------------------------------

fit_and_eval <- function(Xtr, ytr, Xte, yte) {
  res <- list()

  # 1) OLS + Year FE
  ols <- lm.fit(x = Xtr, y = ytr)
  pred_ols <- as.vector(Xte %*% coef(ols))
  res$OLS_YearFE <- c(
    RMSE = rmse(pred_ols, yte),
    MAE  = mae(pred_ols, yte),
    Bias = bias(pred_ols, yte),
    SignAcc = sign_acc(pred_ols, yte, prev = NULL)
  )

  # 2) LASSO（CV）
  cvfit <- cv.glmnet(x = Xtr, y = ytr, alpha = 1, nfolds = 5,
                     family = "gaussian", standardize = TRUE)
  pred_lasso <- as.vector(predict(cvfit, newx = Xte, s = "lambda.min"))
  res$LASSO_CV <- c(
    RMSE = rmse(pred_lasso, yte),
    MAE  = mae(pred_lasso, yte),
    Bias = bias(pred_lasso, yte),
    SignAcc = sign_acc(pred_lasso, yte, prev = NULL)
  )

  # 3) Random Forest（ranger
  rf_block <- function(Xtr, ytr, Xte) {
    keep_cols <- setdiff(colnames(Xtr), "(Intercept)")
    Xtr <- Xtr[, keep_cols, drop = FALSE]
    Xte <- Xte[, keep_cols, drop = FALSE]

    tr_names <- make.names(colnames(Xtr), unique = TRUE)
    te_names <- make.names(colnames(Xte), unique = TRUE)
    colnames(Xtr) <- tr_names
    colnames(Xte) <- te_names

    missing_in_te <- setdiff(tr_names, colnames(Xte))
    if (length(missing_in_te) > 0) {
      for (nm in missing_in_te) Xte <- cbind(Xte, setNames(data.frame(0), nm))
    }
    Xte <- Xte[, tr_names, drop = FALSE]

    Xtr_df <- as.data.frame(Xtr)
    Xte_df <- as.data.frame(Xte)
    rf <- ranger(
      data = data.frame(y = ytr, Xtr_df),
      formula = y ~ .,
      num.trees = 500,
      mtry = max(3, floor(ncol(Xtr_df)/3)),
      min.node.size = 5, seed = 99
    )
    predict(rf, data = Xte_df)$predictions
  }

  pred_rf <- rf_block(Xtr, ytr, Xte)
  res$RF <- c(
    RMSE = rmse(pred_rf, yte),
    MAE  = mae(pred_rf, yte),
    Bias = bias(pred_rf, yte),
    SignAcc = sign_acc(pred_rf, yte, prev = NULL)
  )

  bind_rows(res, .id = "Model")
}

```



```{r}
# ------------------------------
# A3/B1 loop: Three scenes, each repeated B times
# ------------------------------

# —— robustness：A3（×1.5 Variance amplification）——
sc_res_a3 <- list()
for (sc in c("A1","A2","C2")) {
  dgp <- simulate_DGP(sc, a3_sigma_mult = 1.5)
  sc_res_a3[[sc]] <- fit_and_eval(dgp$X_pre, dgp$y_pre, dgp$X_post, dgp$y_post) %>%
    mutate(rep = 1, scenario = paste0(sc,"+A3x1.5"))
}
robust_a3 <- bind_rows(sc_res_a3)

# —— robustness：B1（mean+10%，var×1.2，Rural proport +10pp）——
sc_res_b1 <- list()
for (sc in c("A1","A2","C2")) {
  dgp <- simulate_DGP(sc, b1_shift = list(mu_shift = 0.10, sd_scale = 1.2, rural_pp = +0.10))
  sc_res_b1[[sc]] <- fit_and_eval(dgp$X_pre, dgp$y_pre, dgp$X_post, dgp$y_post) %>%
    mutate(rep = 1, scenario = paste0(sc,"+B1"))
}
robust_b1 <- bind_rows(sc_res_b1)

```

```{r}
# A3：Later error variance amplification（ ×1.5）
robust_a3 <- lapply(c("A1","A2","C2"), function(sc){
  dgp <- simulate_DGP(sc, a3_sigma_mult = 1.5)
  fit_and_eval(dgp$X_pre, dgp$y_pre, dgp$X_post, dgp$y_post) |>
    dplyr::mutate(rep = 1, scenario = paste0(sc, "+A3x1.5"))
}) |> dplyr::bind_rows()

# B1：Covariate shift（mean +10%，var ×1.2，Rural proportion+10pp）
`%||%` <- function(a,b) if(!is.null(a)) a else b   
robust_b1 <- lapply(c("A1","A2","C2"), function(sc){
  dgp <- simulate_DGP(sc, b1_shift = list(mu_shift = 0.10, sd_scale = 1.2, rural_pp = +0.10))
  fit_and_eval(dgp$X_pre, dgp$y_pre, dgp$X_post, dgp$y_post) |>
    dplyr::mutate(rep = 1, scenario = paste0(sc, "+B1"))
}) |> dplyr::bind_rows()

robust_a3b1 <- lapply(c("A1","A2","C2"), function(sc){
  dgp <- simulate_DGP(sc, a3_sigma_mult = 1.5, b1_shift = list(mu_shift = 0.05, sd_scale = 1.1, rural_pp = +0.10))
  fit_and_eval(dgp$X_pre, dgp$y_pre, dgp$X_post, dgp$y_post) |>
    dplyr::mutate(rep = 1, scenario = paste0(sc, "+A3x1.5+B1"))
}) |> dplyr::bind_rows()

results_df <- dplyr::bind_rows(robust_a3, robust_b1, robust_a3b1)

```



```{r}
# ------------------------------
# 7) Summarize
# ------------------------------
summary_tbl <- results_df %>%
  group_by(scenario, Model) %>%
  summarise(
    RMSE_mean = mean(RMSE), RMSE_sd = sd(RMSE),
    MAE_mean  = mean(MAE),  MAE_sd  = sd(MAE),
    Bias_mean = mean(Bias), Bias_sd = sd(Bias),
    SignAcc_mean = mean(SignAcc), SignAcc_sd = sd(SignAcc),
    .groups = "drop"
  ) %>%
  arrange(scenario, RMSE_mean)

write_csv(results_df, "simulation_results_all_reps.csv")
write_csv(summary_tbl, "simulation_results_summary.csv")

p <- summary_tbl %>%
  mutate(Model = factor(Model, levels = c("OLS_YearFE","LASSO_CV","RF"))) %>%
  ggplot(aes(x = Model, y = RMSE_mean)) +
  geom_col() +
  facet_wrap(~scenario, scales = "free_y") +
  geom_errorbar(aes(ymin = RMSE_mean - RMSE_sd, ymax = RMSE_mean + RMSE_sd), width = .2) +
  labs(title = "Simulation RMSE by Scenario (mean ± sd over reps)",
       x = NULL, y = "RMSE") +
  theme_minimal(base_size = 13)
ggsave("simulation_rmse_bar.png", p, width = 9, height = 4.8, dpi = 200)

message("Done：",
        "\n- simulation_results_all_reps.csv",
        "\n- simulation_results_summary.csv",
        "\n- simulation_rmse_bar.png")

```



